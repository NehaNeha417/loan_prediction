{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Traffic_signal_using_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMuohuXnaRNQ2xPMDAea/1o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NehaNeha417/loan_prediction/blob/master/Traffic_signal_using_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceQgUpRdWDrd",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9WBK3EUWEuz",
        "colab_type": "text"
      },
      "source": [
        "TASK #2: IMPORT LIBRARIES/DATASETS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccNsVyudFXmI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b5fdcbc8-eac6-46fc-b3ba-95c3867392f6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uj1nXFoxFXjr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "65a86b42-f55f-409c-f2ec-cfc3dd0c3979"
      },
      "source": [
        "with open(\"./traffic-signs-data/train.p\", mode='rb') as training_data:\n",
        "    train = pickle.load(training_data)\n",
        "with open(\"./traffic-signs-data/valid.p\", mode='rb') as validation_data:\n",
        "    valid = pickle.load(validation_data)\n",
        "with open(\"./traffic-signs-data/test.p\", mode='rb') as testing_data:\n",
        "    test = pickle.load(testing_data)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-5d6973f19904>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./traffic-signs-data/train.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./traffic-signs-data/valid.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./traffic-signs-data/test.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtesting_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './traffic-signs-data/train.p'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow639dQCFXe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,y_train = train['features'], train['labels']\n",
        "X_validation, y_validation = valid['features'], valid['labels']\n",
        "X_test,y_test = test['features'],test['labels']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_ivYFgvFXdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.shape\n",
        "X_validation.shape\n",
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWVnYe4wWdAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train.shape\n",
        "y_validation.shape\n",
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwt4VsWCV7wU",
        "colab_type": "text"
      },
      "source": [
        "Version 2b4c821e5aNotification: Expanded view - Host turned off expand view"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6W84U9VEFXZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = np.random.randint(1, len(X_train))\n",
        "plt.imshow(X_train[i])\n",
        "y_train[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByggXd6jFXXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's view more images in a grid format\n",
        "# Define the dimensions of the plot grid \n",
        "W_grid = 10\n",
        "L_grid = 10\n",
        "\n",
        "# fig, axes = plt.subplots(L_grid, W_grid)\n",
        "# subplot return the figure object and axes object\n",
        "# we can use the axes object to plot specific figures at various locations\n",
        "\n",
        "fig, axes = plt.subplots(L_grid, W_grid, figsize = (10,10))\n",
        "\n",
        "axes = axes.ravel() # flaten the 5 x 5 matrix into 25 array\n",
        "n_training = len(X_train) # get the length of the training dataset\n",
        "\n",
        "# Select a random number from 0 to n_training\n",
        "# create evenly spaces variablesc\n",
        "for i in np.arange(0,W_grid * L_grid):\n",
        "    # select a random number\n",
        "    index = np.random.randint(0,n_training)\n",
        "    # read and display an image with the selected box\n",
        "    axes[i].imshow(X_train[index])\n",
        "    axes[i].set_title(y_train[index], fontsize=15)\n",
        "    axes[i].axis('off')\n",
        "plt.subplots_adjust(hspace=0.4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQsPs_csVxeH",
        "colab_type": "text"
      },
      "source": [
        "TASK #4: CONVERT IMAGES TO GRAYSCALE AND PERFORM NORMALIZATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXXEYaVDFXSu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "X_train,y_train = shuffle(X_train,y_train)\n",
        "X_validation,y_validation = shuffle(X_validation,y_validation)\n",
        "X_test,y_test = shuffle(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsgB__J5Oliu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_gray = np.sum(X_train/3, axis = 3, keepdims = True) \n",
        "X_validation_gray = np.sum(X_validation/3, axis = 3, keepdims = True) \n",
        "X_test_gray = np.sum(X_test/3, axis = 3, keepdims = True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKevA6wMOlrc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_gray.shape\n",
        "X_validation_gray.shape\n",
        "X_test_gray.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z9i2JloOloM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_gray_norm =(X_train_gray-128)/128\n",
        "X_validation_gray_norm = (X_validation_gray-128)/128\n",
        "X_test_gray_norm =(X_test_gray-128)/128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSteqLZYOlfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_gray_norm\n",
        "X_validation_gray_norm\n",
        "X_test_gray_norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptvbEtS8Oldb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = random.randint(1, len(X_train_gray))\n",
        "plt.imshow(X_train_gray[i].squeeze(), cmap = 'gray')\n",
        "plt.figure()\n",
        "plt.imshow(X_train[i])\n",
        "plt.figure()\n",
        "plt.imshow(X_train_gray_norm[i].squeeze(), cmap = 'gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkBMGEaeVkMG",
        "colab_type": "text"
      },
      "source": [
        "TASK #5: UNDERSTAND THE THEORY AND INTUITION BEHIND CONVOLUTIONAL NEURAL NETWORKS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOqvxlC7VdIn",
        "colab_type": "text"
      },
      "source": [
        "TASK #6: BUILD DEEP CONVOLUTIONAL NEURAL NETWORK MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHEtLyBZPE1e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import datasets, layers, models\n",
        "CNN = models.Sequential()\n",
        "CNN.add(layers.Conv2D(6, (5,5), activation = 'relu', input_shape = (32,32,1)))\n",
        "CNN.add(layers.AveragePooling2D())\n",
        "\n",
        "CNN.add(layers.Dropout(0.2))\n",
        "\n",
        "CNN.add(layers.Conv2D(16, (5,5), activation = 'relu'))\n",
        "CNN.add(layers.AveragePooling2D())\n",
        "\n",
        "CNN.add(layers.Flatten())\n",
        "\n",
        "CNN.add(layers.Dense(120,activation='relu'))\n",
        "CNN.add(layers.Dense(84, activation='relu'))\n",
        "CNN.add(layers.Dense(43,activation='softmax'))\n",
        "CNN.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnJrdNOyVWrh",
        "colab_type": "text"
      },
      "source": [
        "TASK #7: COMPILE AND TRAIN DEEP CNN MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I08MT48ZPE8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CNN.compile(optimizer='Adam', loss = 'sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2Pns-H5PE5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = CNN.fit(X_train_gray_norm,\n",
        "                 y_train,\n",
        "                 batch_size=500,\n",
        "                 epochs=25,\n",
        "                 verbose=1,\n",
        "                 validation_data=(X_validation_gray_norm,y_validation))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWURRNC1VPDi",
        "colab_type": "text"
      },
      "source": [
        "TASK #8: ASSESS TRAINED CNN MODEL PERFORMANCEÂ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnxWkQhfPEy-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = CNN.evaluate(X_test_gray_norm, y_test)\n",
        "print('Test Accuracy: {}'.format(score[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWvWiTTAULKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history.history.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mftTx4FYULPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_csv8GoULHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = range(len(accuracy))\n",
        "plt.plot(epochs,loss,'ro', label = 'Training Loss')\n",
        "plt.plot(epochs,val_loss,'r',label = 'Validation Loss')\n",
        "plt.title('Trainind and Validation Loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-2J4Rn-ULFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = range(len(accuracy))\n",
        "plt.plot(epochs,accuracy,'ro', label = 'Training Accuracy')\n",
        "plt.plot(epochs,val_accuracy,'r',label = 'Validation Accuracy')\n",
        "plt.title('Trainind and Validation Accuracy')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOFWS5YbUjOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_classes = CNN.predict_classes(X_test_gray_norm)\n",
        "y_true = y_test\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_true, predicted_classes)\n",
        "plt.figure(figsize = (25, 25))\n",
        "sns.heatmap(cm, annot = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U52PY52UohT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "L = 5\n",
        "W = 5\n",
        "\n",
        "fig, axes = plt.subplots(L, W, figsize = (12, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i in np.arange(0, L*W):\n",
        "    axes[i].imshow(X_test[i])\n",
        "    axes[i].set_title('Prediction = {}\\n True = {}'.format(predicted_classes[i], y_true[i]))\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.subplots_adjust(wspace = 1)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MptpqZvU2Hl",
        "colab_type": "text"
      },
      "source": [
        "In this case study, we want to classify images of traffic signs using deep Convolutional Neural Networks (CNNs).\n",
        "\n",
        "The dataset consists of 43 different classes of images.\n",
        "\n",
        "Classes are as listed below:\n",
        "\n",
        "0 = Speed limit (20km/h)\n",
        "1 = Speed limit (30km/h)\n",
        "2 = Speed limit (50km/h)\n",
        "3 = Speed limit (60km/h)\n",
        "4 = Speed limit (70km/h)\n",
        "5 = Speed limit (80km/h)\n",
        "6 = End of speed limit (80km/h)\n",
        "7 = Speed limit (100km/h)\n",
        "8 = Speed limit (120km/h)\n",
        "9 = No passing\n",
        "10 = No passing for vehicles over 3.5 metric tons\n",
        "11 = Right-of-way at the next intersection\n",
        "12 = Priority road\n",
        "13 = Yield\n",
        "14 = Stop\n",
        "15 = No vehicles\n",
        "16 = Vehicles over 3.5 metric tons prohibited\n",
        "17 = No entry\n",
        "18 = General caution\n",
        "19 = Dangerous curve to the left\n",
        "20 = Dangerous curve to the right\n",
        "21 = Double curve\n",
        "22 = Bumpy road\n",
        "23 = Slippery road\n",
        "24 = Road narrows on the right\n",
        "25 = Road work\n",
        "26 = Traffic signals\n",
        "27 = Pedestrians\n",
        "28 = Children crossing\n",
        "29 = Bicycles crossing\n",
        "30 = Beware of ice/snow\n",
        "31 = Wild animals crossing\n",
        "32 = End of all speed and passing limits\n",
        "33 = Turn right ahead\n",
        "34 = Turn left ahead\n",
        "35 = Ahead only\n",
        "36 = Go straight or right\n",
        "37 = Go straight or left\n",
        "38 = Keep right\n",
        "39 = Keep left\n",
        "40 = Roundabout mandatory\n",
        "41 = End of no passing\n",
        "42 = End of no passing by vehicles over 3.5 metric tons\n",
        "Citation J. Stallkamp, M. Schlipsing, J. Salmen, and C. Igel. The German Traffic Sign Recognition Benchmark: A multi-class classification competition. In Proceedings of the IEEE International Joint Conference on Neural Networks, pages 1453Â1460. 2011. @inproceedings{Stallkamp-IJCNN-2011, author = {Johannes Stallkamp and Marc Schlipsing and Jan Salmen and Christian Igel}, booktitle = {IEEE International Joint Conference on Neural Networks}, title = {The {G}erman {T}raffic {S}ign {R}ecognition {B}enchmark: A multi-class classification competition}, year = {2011}, pages = {1453--1460} }"
      ]
    }
  ]
}